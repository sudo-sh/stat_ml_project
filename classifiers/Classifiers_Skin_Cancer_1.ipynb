{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classifiers_Skin_Cancer_1.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1_QnCt5ROPGifCQe0rLT6TxIarPkdBkfu","authorship_tag":"ABX9TyPV2LwF6dyXNshpOmc0qs7n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -U memory_profiler"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJdGT8a1VUaM","executionInfo":{"status":"ok","timestamp":1651855862909,"user_tz":240,"elapsed":5368,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"39e3e085-5ad7-465a-a7e3-70b519a3d42e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting memory_profiler\n","  Downloading memory_profiler-0.60.0.tar.gz (38 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n","Building wheels for collected packages: memory-profiler\n","  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for memory-profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31284 sha256=489b758d23eb84262d034fa441f39a7abb816f83eb42372bc8db4dfe76157a4e\n","  Stored in directory: /root/.cache/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f\n","Successfully built memory-profiler\n","Installing collected packages: memory-profiler\n","Successfully installed memory-profiler-0.60.0\n"]}]},{"cell_type":"code","execution_count":12,"metadata":{"id":"8GsJY1pXGPjB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651857201560,"user_tz":240,"elapsed":315,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"8b80674e-a062-4af9-b913-508e1400cb3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train = (1531, 500)\n","x_val = (271, 500)\n","x_test = (318, 500)\n","y_train = (1531,)\n","y_val = (271,)\n","y_test = (318,)\n"]}],"source":["#https://www.kaggle.com/datasets/hasinisadunikasilva/skincancerdetectiondcnn\n","\n","#Import all necessary libraries\n","import time\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn import metrics\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import svm #SVM Classifier\n","from sklearn import neighbors #KNN Classifier\n","from memory_profiler import profile #For memory usage profiling\n","from sklearn.metrics import confusion_matrix #For specificity and sensitivity metrics\n","from sklearn.neural_network import MLPClassifier #Multi-Layer Perceptron Classifier\n","from sklearn.naive_bayes import GaussianNB #Gaussian Naive Bayes Classifier\n","from sklearn.linear_model import LogisticRegression #Logistic Regression Classifier\n","from sklearn.preprocessing import StandardScaler #Used to standardize data (0 mean and unit variance)\n","from sklearn.preprocessing import MinMaxScaler #Used to normalize data between 0 and 1\n","\n","#Ignore those pesky warnings\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","#Load in data from files\n","dir_path = 'drive/MyDrive/Georgia Tech/Classes/Spring 2022/ECE 6254: Statistical Machine Learning/Final Project/skin_cancer_dataset_1/'\n","x_train = np.load(dir_path + 'train_data.npy')\n","y_train = np.load(dir_path + 'train_label.npy')\n","x_val = np.load(dir_path + 'val_data.npy')\n","y_val = np.load(dir_path + 'val_label.npy')\n","x_test = np.load(dir_path + 'test_data.npy')\n","y_test = np.load(dir_path + 'test_label.npy')\n","\n","#Check their shape\n","print(\"x_train = \" + str(x_train.shape))\n","print(\"x_val = \" + str(x_val.shape))\n","print(\"x_test = \" + str(x_test.shape))\n","print(\"y_train = \" + str(y_train.shape))\n","print(\"y_val = \" + str(y_val.shape))\n","print(\"y_test = \" + str(y_test.shape))"]},{"cell_type":"code","source":["#Perform preprocessing of data for certain algorithms\n","\n","#Scale the data to 0 mean and unit variance\n","standard = StandardScaler()\n","x_train_standard = standard.fit_transform(x_train)\n","x_val_standard = standard.transform(x_val)\n","x_test_standard = standard.transform(x_test)\n","\n","#Normalize data to be between 0 and 1 since some algorithms (KNN) use Euclidean distance as a metric\n","normal = MinMaxScaler(feature_range=(0, 1))\n","x_train_normal = normal.fit_transform(x_train)\n","x_val_normal = normal.transform(x_val)\n","x_test_normal = normal.transform(x_test)\n","\n","#Combine validation and test sets for algorithms which don't require parameter tuning\n","x_test_val = np.concatenate((x_val, x_test))\n","y_test_val = np.concatenate((y_val, y_test))\n","x_test_val_standard = standard.transform(x_test_val)\n","x_test_val_normal = normal.transform(x_test_val)"],"metadata":{"id":"92YcDTyMQKx_","executionInfo":{"status":"ok","timestamp":1651855871846,"user_tz":240,"elapsed":93,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#Train the KNN Classifier\n","def KNN_Classifier():\n","\n","  print(\"Training the KNN Classifier!\\n\")\n","\n","  #Declare variables used for k parameter sweep\n","  k_optimal = 1\n","  k_range = 100\n","  accuracy_KNN = 0.0\n","  accuracy_val = 0.0\n","\n","  #Train KNN Classifier and find k which yields maximum accuracy\n","  for k in range(1, k_range+1):\n","    KNN_clf = neighbors.KNeighborsClassifier(n_neighbors=k, weights='uniform')\n","    KNN_clf.fit(x_train, y_train)\n","    accuracy = KNN_clf.score(x_val, y_val)\n","    #print(\"k = \" + str(k) + \", Accuracy = \" + str(accuracy))\n","\n","    if accuracy > accuracy_val:\n","      k_optimal = k\n","      accuracy_val = accuracy\n","\n","  KNN_clf = neighbors.KNeighborsClassifier(n_neighbors=k_optimal, weights='uniform')\n","  KNN_clf.fit(x_train, y_train)\n","  train_accuracy = KNN_clf.score(x_train, y_train)\n","\n","  #Find the average runtime on the testing set\n","  num_runs = 20\n","  avg_time_KNN = 0.0\n","  for i in range(0, num_runs):\n","    start_time = time.time()\n","    accuracy_KNN = KNN_clf.score(x_test, y_test)\n","    avg_time_KNN += time.time() - start_time\n","  avg_time_KNN /= num_runs\n","  avg_time_KNN = str(round(avg_time_KNN, 4))\n","\n","  #Calculate sensitivity and specificity metrics\n","  y_pred_KNN = KNN_clf.predict(x_test)\n","  tn, fp, fn, tp = confusion_matrix(y_test, y_pred_KNN).ravel()\n","  specificity_KNN = tn / (tn+fp)\n","  sensitivity_KNN = tp / (tp+fn)\n","\n","  print(\"KNN Classifier Accuracy on Training Set = \" + str(train_accuracy))\n","  print(\"KNN Classifier Accuracy on Test Set = \" + str(accuracy_KNN))\n","  print(\"KNN Classifier Sensitivity on Test Set = \" + str(sensitivity_KNN))\n","  print(\"KNN Classifier Specificity on Test Set = \" + str(specificity_KNN))\n","  print(\"Optimal value of k = \" + str(k_optimal))\n","  print(\"Average Runtime of KNN Classifer on Test Set = \" + str(avg_time_KNN) + \" seconds\")\n","\n","KNN_Classifier()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G6V3ItdJQBEO","executionInfo":{"status":"ok","timestamp":1651859156066,"user_tz":240,"elapsed":10705,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"f61a8728-1f85-4770-c637-4f37601709c2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the KNN Classifier!\n","\n","KNN Classifier Accuracy on Training Set = 1.0\n","KNN Classifier Accuracy on Test Set = 0.6823899371069182\n","KNN Classifier Sensitivity on Test Set = 0.569620253164557\n","KNN Classifier Specificity on Test Set = 0.79375\n","Optimal value of k = 1\n","Average Runtime of KNN Classifer on Test Set = 0.0728 seconds\n"]}]},{"cell_type":"code","source":["#Train the Logistic Regression Classifier\n","def LogReg_Classifier():\n","  \n","  print(\"Training the Logistic Regression Classifier!\\n\")\n","\n","  #Global parameter variables\n","  l1_ratio = 'none'\n","  penalty = 'l2'\n","  solver = 'lbfgs'\n","  C = 1\n","\n","  #Fine-tune C parameter and penalty/solver choices for maximum accuracy\n","  C_arr = [0.00001, 0.0005, .001, 0.005, 0.01, 0.05, 0.1]\n","  solvers = ['newton-cg', 'lbfgs', 'sag']\n","  penalties = ['l2']\n","\n","  max_val_accuracy = 0.0\n","\n","  #Perform the parameter sweep\n","  for sol in solvers:\n","    for pen in penalties:\n","      for CC in C_arr:\n","        LogReg_clf = LogisticRegression(penalty=pen, C=CC, solver=sol, max_iter=1000)\n","        LogReg_clf.fit(x_train_normal, y_train)\n","\n","        #Compute the classifier accuracy on the validation set\n","        val_accuracy = LogReg_clf.score(x_val_normal, y_val)\n","\n","        if val_accuracy > max_val_accuracy:\n","          C = CC\n","          solver = sol\n","          penalty = pen\n","          max_val_accuracy = val_accuracy\n","\n","  #Repeat the parameter sweep for the 'saga' solver which uses the elastic net penalty\n","  C_arr = [0.00001, 0.0005, .001, 0.005, 0.01, 0.05, 0.1]\n","  solvers = ['saga']\n","  penalties = ['elasticnet', 'l1', 'l2']\n","  l1_ratios = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n","\n","  #Perform the parameter sweep\n","  for sol in solvers:\n","    for pen in penalties:\n","      for CC in C_arr:\n","        for ratio in l1_ratios:\n","          LogReg_clf = LogisticRegression(penalty=pen, C=CC, solver=sol, l1_ratio=ratio, max_iter=1000)\n","          LogReg_clf.fit(x_train_normal, y_train)\n","\n","          #Compute the classifier accuracy on the validation set\n","          val_accuracy = LogReg_clf.score(x_val_normal, y_val)\n","\n","          if val_accuracy > max_val_accuracy:\n","            C = CC\n","            solver = sol\n","            penalty = pen\n","            l1_ratio = ratio\n","            max_val_accuracy = val_accuracy\n","\n","  #Based on the validation set, set the parameter values of the optimal logistic regression algorithm\n","  LogReg_clf = LogisticRegression(penalty=penalty, C=C, solver=solver, l1_ratio=l1_ratio, max_iter=1000)\n","  LogReg_clf.fit(x_train_normal, y_train)\n","  train_accuracy = LogReg_clf.score(x_train_normal, y_train)\n","\n","  #Find the average runtime on the testing set\n","  num_runs = 20\n","  avg_time_LogReg = 0.0\n","  for i in range(0, num_runs):\n","    start_time = time.time()\n","    test_accuracy = LogReg_clf.score(x_test_normal, y_test)\n","    avg_time_LogReg += (time.time() - start_time)\n","  avg_time_LogReg /= num_runs\n","  avg_time_LogReg = str(round(avg_time_LogReg, 4))\n","\n","  #Calculate sensitivity and specificity metrics\n","  y_pred_LogReg = LogReg_clf.predict(x_test_normal)\n","  tn, fp, fn, tp = confusion_matrix(y_test, y_pred_LogReg).ravel()\n","  specificity_LogReg = tn / (tn+fp)\n","  sensitivity_LogReg = tp / (tp+fn)\n","\n","  print(\"Logistic Regression Classifier Accuracy on Test Set = \" + str(test_accuracy))\n","  print(\"Logistic Regression Classifier Accuracy on Training Set = \" + str(train_accuracy))\n","  print(\"Logistic Regression Classifier Sensitivity on Test Set = \" + str(sensitivity_LogReg))\n","  print(\"Logistic Regression Classifier Specificity on Test Set = \" + str(specificity_LogReg))\n","  print(\"Parameters:\")\n","  print(\"   C = \" + str(C))\n","  print(\"   Penalty = \" + str(penalty))\n","  print(\"   Solver = \" + str(solver))\n","  print(\"   L1 Ratio = \" + str(l1_ratio))\n","  print(\"Average Runtime of Logistic Regression Classifer on Test Set = \" + str(avg_time_LogReg) + \" seconds\")\n","\n","LogReg_Classifier()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82i5N-H2vCQW","executionInfo":{"status":"ok","timestamp":1651802626031,"user_tz":240,"elapsed":92179,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"782cffe6-b804-4679-fb71-9ba792586c0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the Logistic Regression Classifier!\n","\n","Logistic Regression Classifier Accuracy on Test Set = 0.6792452830188679\n","Logistic Regression Classifier Accuracy on Training Set = 0.8288700195950359\n","Logistic Regression Classifier Sensitivity on Test Set = 0.6835443037974683\n","Logistic Regression Classifier Specificity on Test Set = 0.675\n","Parameters:\n","   C = 0.05\n","   Penalty = l2\n","   Solver = sag\n","   L1 Ratio = none\n","Average Runtime of Logistic Regression Classifer on Test Set = 0.0008 seconds\n"]}]},{"cell_type":"code","source":["#Train the Support Vector Machine Classifier\n","def SVM_Classifier():\n","  \n","  print(\"Training the SVM Classifier!\\n\")\n","\n","  #Perform a parameter sweep for the kernel type and C value\n","  C_arr = [0.00001, 0.0005, .001, 0.005, 0.01, 0.05, 0.1]\n","  C = 1\n","  kernel = 'rbf'\n","  degree = 'none'\n","  max_val_accuracy = 0.0\n","\n","  #Sweep 1: Test the linear kernel\n","  print(\"Training SVM Classifier with a linear kernel...\")\n","\n","  for C_val in C_arr:\n","      SVM_clf = svm.SVC(C=C_val, kernel='linear')\n","      SVM_clf.fit(x_train, y_train)\n","\n","      #Compute the classifier accuracy on the validation set\n","      val_accuracy = SVM_clf.score(x_val, y_val)\n","\n","      if val_accuracy > max_val_accuracy:\n","        C = C_val\n","        kernel = 'linear'\n","        max_val_accuracy = val_accuracy\n","\n","  #Sweep 2: Test the polynomial kernel\n","  print(\"Training SVM Classifier with a polynomial kernel...\")\n","\n","  for deg in [1,2,3,4,5,6,7,8,9,10]:\n","      print(\"   Training degree = \" + str(deg) + \"...\")\n","      for C_val in C_arr:\n","        SVM_clf = svm.SVC(C=C_val, kernel='poly', degree=deg)\n","        SVM_clf.fit(x_train, y_train)\n","\n","        #Compute the classifier accuracy on the validation set\n","        val_accuracy = SVM_clf.score(x_val, y_val)\n","\n","        if val_accuracy > max_val_accuracy:\n","          C = C_val\n","          kernel = 'poly'\n","          degree = deg\n","          max_val_accuracy = val_accuracy\n","\n","  #Sweep 3: Test the rbf kernel\n","  print(\"Training SVM Classifier with a RBF kernel...\")\n","\n","  for C_val in C_arr:\n","      SVM_clf = svm.SVC(C=C_val, kernel='rbf')\n","      SVM_clf.fit(x_train, y_train)\n","\n","      #Compute the classifier accuracy on the validation set\n","      val_accuracy = SVM_clf.score(x_val, y_val)\n","\n","      if val_accuracy > max_val_accuracy:\n","        C = C_val\n","        kernel = 'rbf'\n","        max_val_accuracy = val_accuracy\n","\n","  #Sweep 4: Test the sigmoid kernel\n","  print(\"Training SVM Classifier with a sigmoid kernel...\")\n","\n","  for C_val in C_arr:\n","      SVM_clf = svm.SVC(C=C_val, kernel='sigmoid')\n","      SVM_clf.fit(x_train, y_train)\n","\n","      #Compute the classifier accuracy on the validation set\n","      val_accuracy = SVM_clf.score(x_val, y_val)\n","\n","      if val_accuracy > max_val_accuracy:\n","        C = C_val\n","        kernel = 'sigmoid'\n","        max_val_accuracy = val_accuracy\n","\n","  #Based on the validation set, set the parameter values of the optimal SVM algorithm\n","  SVM_clf = svm.SVC(C=C, kernel=kernel, degree=deg)\n","  SVM_clf.fit(x_train, y_train)\n","  train_accuracy = SVM_clf.score(x_train, y_train)\n","  test_accuracy = SVM_clf.score(x_test, y_test)\n","  num_SVs = len(SVM_clf.support_vectors_)\n","\n","  #Find the average runtime on the testing set\n","  num_runs = 20\n","  avg_time_SVM = 0.0\n","  for i in range(0, num_runs):\n","    start_time = time.time()\n","    test_accuracy = SVM_clf.score(x_test, y_test)\n","    avg_time_SVM += (time.time() - start_time)\n","  avg_time_SVM /= num_runs\n","  avg_time_SVM = str(round(avg_time_SVM, 4))\n","\n","  #Calculate sensitivity and specificity metrics\n","  y_pred_SVM = SVM_clf.predict(x_test)\n","  tn, fp, fn, tp = confusion_matrix(y_test, y_pred_SVM).ravel()\n","  specificity_SVM = tn / (tn+fp)\n","  sensitivity_SVM = tp / (tp+fn)\n","\n","  print(\"\\n\")\n","  print(\"SVM Classifier Accuracy on Test Set = \" + str(test_accuracy))\n","  print(\"SVM Classifier Accuracy on Training Set = \" + str(train_accuracy))\n","  print(\"SVM Classifier Sensitivity on Test Set = \" + str(sensitivity_SVM))\n","  print(\"SVM Classifier Specificity on Test Set = \" + str(specificity_SVM))\n","  print(\"Number of support vectors = \" + str(num_SVs))\n","  print(\"Parameters:\")\n","  print(\"   C = \" + str(C))\n","  print(\"   Kernel = \" + str(kernel))\n","  print(\"   Degree = \" + str(degree))\n","  print(\"Average Runtime of SVM Classifer on Test Set = \" + str(avg_time_SVM) + \" seconds\")\n","\n","SVM_Classifier()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVx5A_JBUfLM","executionInfo":{"status":"ok","timestamp":1651806986695,"user_tz":240,"elapsed":73821,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"4a58dffb-e017-4766-8470-c0a8f93e5b82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the SVM Classifier!\n","\n","Training SVM Classifier with a linear kernel...\n","Training SVM Classifier with a polynomial kernel...\n","   Training degree = 1...\n","   Training degree = 2...\n","   Training degree = 3...\n","   Training degree = 4...\n","   Training degree = 5...\n","   Training degree = 6...\n","   Training degree = 7...\n","   Training degree = 8...\n","   Training degree = 9...\n","   Training degree = 10...\n","Training SVM Classifier with a RBF kernel...\n","Training SVM Classifier with a sigmoid kernel...\n","\n","\n","SVM Classifier Accuracy on Test Set = 0.7044025157232704\n","SVM Classifier Accuracy on Training Set = 0.8190725016329197\n","SVM Classifier Sensitivity on Test Set = 0.6962025316455697\n","SVM Classifier Specificity on Test Set = 0.7125\n","Number of support vectors = 1118\n","Parameters:\n","   C = 0.05\n","   Kernel = linear\n","   Degree = none\n","Average Runtime of SVM Classifer on Test Set = 0.0575 seconds\n"]}]},{"cell_type":"code","source":["#Train the Gaussian Naive Bayes Classifier\n","def NB_Classifier():\n","  \n","  print(\"Training the Gaussian Naive Bayes Classifier!\\n\")\n","\n","  NB_clf = GaussianNB()\n","  NB_clf.fit(x_train_standard, y_train)\n","  train_accuracy = NB_clf.score(x_train_standard, y_train)\n","\n","  #Find the average runtime on the testing set\n","  num_runs = 20\n","  avg_time_NB = 0.0\n","  for i in range(0, num_runs):\n","    start_time = time.time()\n","    test_accuracy = NB_clf.score(x_test_val_standard, y_test_val)\n","    avg_time_NB += (time.time() - start_time)\n","  avg_time_NB /= num_runs\n","  avg_time_NB = str(round(avg_time_NB, 4))\n","\n","  #Calculate sensitivity and specificity metrics\n","  y_pred_NB = NB_clf.predict(x_test_val_standard)\n","  tn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_NB).ravel()\n","  specificity_NB = tn / (tn+fp)\n","  sensitivity_NB = tp / (tp+fn)\n","\n","  print(\"Gaussian Naive Bayes Classifier Accuracy on Test Set = \" + str(test_accuracy))\n","  print(\"Gaussian Naive Bayes Classifier Accuracy on Training Set = \" + str(train_accuracy))\n","  print(\"Gaussian Naive Bayes Classifier Sensitivity on Test Set = \" + str(sensitivity_NB))\n","  print(\"Gaussian Naive Bayes Classifier Specificity on Test Set = \" + str(specificity_NB))\n","  print(\"Average Runtime of Naive Bayes Classifer on Test Set = \" + str(avg_time_NB) + \" seconds\")\n","\n","NB_Classifier()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNlRyd3SDlfY","executionInfo":{"status":"ok","timestamp":1651806907390,"user_tz":240,"elapsed":273,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"edfac33d-2e50-4f6d-b49c-aa927d17239a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the Gaussian Naive Bayes Classifier!\n","\n","Gaussian Naive Bayes Classifier Accuracy on Test Set = 0.6451612903225806\n","Gaussian Naive Bayes Classifier Accuracy on Training Set = 0.6949706074461136\n","Gaussian Naive Bayes Classifier Sensitivity on Test Set = 0.38408304498269896\n","Gaussian Naive Bayes Classifier Specificity on Test Set = 0.8966666666666666\n","Average Runtime of Naive Bayes Classifer on Test Set = 0.005 seconds\n"]}]},{"cell_type":"code","source":["#Train the K-Means Classifier\n","def KM_Classifier():\n","\n","  print(\"Training the K-Means Classifier!\\n\")\n","\n","  from sklearn.metrics.cluster import completeness_score\n","  from sklearn.cluster import KMeans\n","\n","  KM_clf = KMeans(n_clusters=2, random_state=0, max_iter=1000)\n","  KM_clf.fit(x_train, y_train)\n","\n","  #Find the average runtime on the testing set\n","  num_runs = 20\n","  avg_time_KM = 0.0\n","  for i in range(0, num_runs):\n","    start_time = time.time()\n","    y_pred = KM_clf.predict(x_test_val)\n","    avg_time_KM += (time.time() - start_time)\n","  avg_time_KM /= num_runs\n","  avg_time_KM = str(round(avg_time_KM, 4))\n","\n","  #Manually find the accuracy of the clustering\n","  num_matches = 0\n","  for i in range(len(y_test_val)):\n","    if y_pred[i] == y_test_val[i]:\n","      num_matches += 1\n","  KM_accuracy = num_matches / len(y_test_val)\n","\n","  #Calculate sensitivity and specificity metrics\n","  y_pred_KM = KM_clf.predict(x_test_val)\n","  tn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_KM).ravel()\n","  specificity_KM = tn / (tn+fp)\n","  sensitivity_KM = tp / (tp+fn)\n","\n","  print(\"K-Means Clustering Classifier Accuracy on Test Set = \" + str(KM_accuracy))\n","  print(\"K-Means Clustering Classifier Sensitivity on Test Set = \" + str(sensitivity_KM))\n","  print(\"K-Means Clustering Classifier Specificity on Test Set = \" + str(specificity_KM))\n","  print(\"Average Runtime of K-Means Clustering Classifer on Test Set = \" + str(avg_time_KM) + \" seconds\")\n","\n","KM_Classifier()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H49iSOlEKWYR","executionInfo":{"status":"ok","timestamp":1651803103108,"user_tz":240,"elapsed":1992,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"568062d4-23d9-4e69-a4bb-df8a95a40164"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the K-Means Classifier!\n","\n","K-Means Clustering Classifier Accuracy on Test Set = 0.48217317487266553\n","K-Means Clustering Classifier Sensitivity on Test Set = 0.4013840830449827\n","K-Means Clustering Classifier Specificity on Test Set = 0.56\n","Average Runtime of K-Means Clustering Classifer on Test Set = 0.0133 seconds\n"]}]},{"cell_type":"code","source":["#Train the Multi-Layer Perceptron Classifier\n","def MLP_Classifier():\n","\n","  print(\"Training the Multi-Layer Perceptron Classifier!\\n\")\n","\n","  #Optimize parameters to achieve the highest test accuracy\n","  #The relevant parameters we will optimize are:\n","  #   1) The number of neural network layers\n","  #   2) The number of neurons within each layer\n","  #   3) The activation function\n","  #   4) The solver used for weight optimization\n","  #   5) The alpha value used as the L2 penalty (regularization term) parameter\n","  #Perform a sweep on each parameter separately for efficiency\n","\n","  #Declare optimal parameter variables\n","  highest_accuracy = 0.0\n","  hidden_layer_sizes_opt = ()\n","  activation_opt = ''\n","  solver_opt = ''\n","  alpha_opt = 0.0\n","\n","  #Parameter sweep for the number of layers and size of layers\n","  #Keep other layers at default values\n","  #num_neurons = [10, 25, 50, 75, 100, 125, 150, 175, 200] #Values chosen from observing empirical results\n","  num_neurons = [5, 10, 15, 20, 25, 30, 35, 40] #Values chosen from observing empirical results\n","  num_layers = 3\n","  base_tuple = ()\n","  curr_tuple = ()\n","\n","  print(\"Parameter Sweep for Hidden Layer Configuration:\")\n","  for i in range(1, num_layers+1): #Sweep num_layers layers\n","    best_num = 10\n","    best_local_accuracy = 0.0\n","    for j in num_neurons:\n","\n","      curr_tuple = base_tuple + (j,)\n","      clf = MLPClassifier(hidden_layer_sizes=curr_tuple, random_state=1, max_iter=1000).fit(x_train, y_train)\n","      accuracy = clf.score(x_val, y_val)\n","      print(\"   Testing Layer Configuration: \" + str(curr_tuple) + \",  Validation Accuracy: \" + str(accuracy))\n","\n","      if accuracy > best_local_accuracy:\n","        best_num = j\n","        best_local_accuracy = accuracy\n","\n","      if accuracy > highest_accuracy:\n","        hidden_layer_sizes_opt = curr_tuple\n","        highest_accuracy = accuracy\n","    \n","    base_tuple += (best_num,)\n","  print(\"\\n\")\n","\n","  #Parameter sweep for the activation function\n","  print(\"Parameter Sweep for Activation Function:\")\n","  act_funcs = ['identity', 'logistic', 'tanh', 'relu']\n","  best_local_accuracy = 0.0\n","  for act in act_funcs:\n","    clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes_opt, activation=act, random_state=1, max_iter=1000).fit(x_train, y_train)\n","    accuracy = clf.score(x_val, y_val)\n","    print(\"   Testing Activation Function: \" + act + \",  Validation Accuracy: \" + str(accuracy))\n","\n","    if accuracy > best_local_accuracy:\n","      activation_opt = act\n","      best_local_accuracy = accuracy\n","\n","    if accuracy > highest_accuracy:\n","      activation_opt = act\n","      highest_accuracy = accuracy\n","  print(\"\\n\")\n","\n","  #Parameter sweep for the solver\n","  print(\"Parameter Sweep for Solver:\")\n","  solvers = ['lbfgs', 'sgd', 'adam']\n","  best_local_accuracy = 0.0\n","  for sol in solvers:\n","    clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes_opt, activation=activation_opt, solver=sol, random_state=1, max_iter=1000).fit(x_train, y_train)\n","    accuracy = clf.score(x_val, y_val)\n","    print(\"   Testing Solver: \" + sol + \",  Validation Accuracy: \" + str(accuracy))\n","\n","    if accuracy > best_local_accuracy:\n","      solver_opt = sol\n","      best_local_accuracy = accuracy\n","\n","    if accuracy > highest_accuracy:\n","      solver_opt = sol\n","      highest_accuracy = accuracy\n","  print(\"\\n\")\n","\n","  #Parameter sweep for alpha\n","  print(\"Parameter Sweep for Alpha:\")\n","  alphas = [0.000001, 0.000005, 0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01]\n","  best_local_accuracy = 0.0\n","  for alpha in alphas:\n","    clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes_opt, activation=activation_opt, solver=solver_opt, alpha=alpha, random_state=1, max_iter=1000).fit(x_train, y_train)\n","    accuracy = clf.score(x_val, y_val)\n","    print(\"   Testing Alpha: \" + str(alpha) + \",  Validation Accuracy: \" + str(accuracy))\n","\n","    if accuracy > best_local_accuracy:\n","      alpha_opt = alpha\n","      best_local_accuracy = accuracy\n","\n","    if accuracy > highest_accuracy:\n","      alpha_opt = alpha\n","      highest_accuracy = accuracy\n","  print(\"\\n\")\n","\n","  # Fit MLPClassifier to the training data using the optimal parameters found previously\n","  clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes_opt, activation=activation_opt, solver=solver_opt, alpha=alpha_opt, random_state=1, max_iter=1000).fit(x_train, y_train)\n","\n","  # Compute the accuracy on the training set and test set\n","  train_accuracy = clf.score(x_train, y_train)\n","\n","  #Find the average runtime on the testing set\n","  num_runs = 20\n","  avg_time_MLP = 0.0\n","  for i in range(0, num_runs):\n","    start_time = time.time()\n","    test_accuracy = clf.score(x_test, y_test)\n","    avg_time_MLP += (time.time() - start_time)\n","  avg_time_MLP /= num_runs\n","  avg_time_MLP = str(round(avg_time_MLP, 4))\n","\n","  #Calculate sensitivity and specificity metrics\n","  y_pred_MLP = clf.predict(x_test)\n","  tn, fp, fn, tp = confusion_matrix(y_test, y_pred_MLP).ravel()\n","  specificity_MLP = tn / (tn+fp)\n","  sensitivity_MLP = tp / (tp+fn)\n","\n","  print(\"Multi-Layer Perceptron Classifier Accuracy on Test Set = \" + str(test_accuracy))\n","  print(\"Multi-Layer Perceptron Classifier Accuracy on Training Set = \" + str(train_accuracy))\n","  print(\"Multi-Layer Perceptron Classifier Sensitivity on Test Set = \" + str(sensitivity_MLP))\n","  print(\"Multi-Layer Perceptron Classifier Specificity on Test Set = \" + str(specificity_MLP))\n","  print(\"Optimal Parameters:\")\n","  print(\"   Hidden Layer Configuration: \" + str(hidden_layer_sizes_opt))\n","  print(\"      Number of Layers: \" + str(len(hidden_layer_sizes_opt)))\n","  for i in range(1, len(hidden_layer_sizes_opt)+1):\n","    print(\"      Layer \" + str(i) + \" Size: \" + str(hidden_layer_sizes_opt[i-1]) + \" Neurons\")\n","  print(\"   Activation Function: \" + str(activation_opt))\n","  print(\"   Solver for Weight Optimization: \" + str(solver_opt))\n","  print(\"   Alpha: \" + str(alpha_opt))\n","  print(\"Average Runtime of Multi-Layer Perceptron Classifer on Test Set = \" + str(avg_time_MLP) + \" seconds\")\n","\n","MLP_Classifier()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6GlQK6wg0K8","executionInfo":{"status":"ok","timestamp":1651814428833,"user_tz":300,"elapsed":206013,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"259e3c85-9730-4e81-a0b8-a1808655a206"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the Multi-Layer Perceptron Classifier!\n","\n","Parameter Sweep for Hidden Layer Configuration:\n","   Testing Layer Configuration: (5,),  Validation Accuracy: 0.7306273062730627\n","   Testing Layer Configuration: (10,),  Validation Accuracy: 0.7232472324723247\n","   Testing Layer Configuration: (15,),  Validation Accuracy: 0.7490774907749077\n","   Testing Layer Configuration: (20,),  Validation Accuracy: 0.7527675276752768\n","   Testing Layer Configuration: (25,),  Validation Accuracy: 0.7490774907749077\n","   Testing Layer Configuration: (30,),  Validation Accuracy: 0.7306273062730627\n","   Testing Layer Configuration: (35,),  Validation Accuracy: 0.7675276752767528\n","   Testing Layer Configuration: (40,),  Validation Accuracy: 0.7380073800738007\n","   Testing Layer Configuration: (35, 5),  Validation Accuracy: 0.7785977859778598\n","   Testing Layer Configuration: (35, 10),  Validation Accuracy: 0.7527675276752768\n","   Testing Layer Configuration: (35, 15),  Validation Accuracy: 0.7638376383763837\n","   Testing Layer Configuration: (35, 20),  Validation Accuracy: 0.7564575645756457\n","   Testing Layer Configuration: (35, 25),  Validation Accuracy: 0.7675276752767528\n","   Testing Layer Configuration: (35, 30),  Validation Accuracy: 0.7564575645756457\n","   Testing Layer Configuration: (35, 35),  Validation Accuracy: 0.7675276752767528\n","   Testing Layer Configuration: (35, 40),  Validation Accuracy: 0.7712177121771218\n","   Testing Layer Configuration: (35, 5, 5),  Validation Accuracy: 0.7416974169741697\n","   Testing Layer Configuration: (35, 5, 10),  Validation Accuracy: 0.7453874538745388\n","   Testing Layer Configuration: (35, 5, 15),  Validation Accuracy: 0.7785977859778598\n","   Testing Layer Configuration: (35, 5, 20),  Validation Accuracy: 0.7490774907749077\n","   Testing Layer Configuration: (35, 5, 25),  Validation Accuracy: 0.8007380073800738\n","   Testing Layer Configuration: (35, 5, 30),  Validation Accuracy: 0.7416974169741697\n","   Testing Layer Configuration: (35, 5, 35),  Validation Accuracy: 0.7822878228782287\n","   Testing Layer Configuration: (35, 5, 40),  Validation Accuracy: 0.7527675276752768\n","\n","\n","Parameter Sweep for Activation Function:\n","   Testing Activation Function: identity,  Validation Accuracy: 0.6678966789667896\n","   Testing Activation Function: logistic,  Validation Accuracy: 0.7306273062730627\n","   Testing Activation Function: tanh,  Validation Accuracy: 0.7564575645756457\n","   Testing Activation Function: relu,  Validation Accuracy: 0.8007380073800738\n","\n","\n","Parameter Sweep for Solver:\n","   Testing Solver: lbfgs,  Validation Accuracy: 0.7896678966789668\n","   Testing Solver: sgd,  Validation Accuracy: 0.8081180811808119\n","   Testing Solver: adam,  Validation Accuracy: 0.8007380073800738\n","\n","\n","Parameter Sweep for Alpha:\n","   Testing Alpha: 1e-06,  Validation Accuracy: 0.8191881918819188\n","   Testing Alpha: 5e-06,  Validation Accuracy: 0.8118081180811808\n","   Testing Alpha: 1e-05,  Validation Accuracy: 0.8118081180811808\n","   Testing Alpha: 5e-05,  Validation Accuracy: 0.8081180811808119\n","   Testing Alpha: 0.0001,  Validation Accuracy: 0.8081180811808119\n","   Testing Alpha: 0.0005,  Validation Accuracy: 0.8154981549815498\n","   Testing Alpha: 0.001,  Validation Accuracy: 0.8118081180811808\n","   Testing Alpha: 0.005,  Validation Accuracy: 0.8154981549815498\n","   Testing Alpha: 0.01,  Validation Accuracy: 0.8118081180811808\n","\n","\n","Multi-Layer Perceptron Classifier Accuracy on Test Set = 0.7578616352201258\n","Multi-Layer Perceptron Classifier Accuracy on Training Set = 0.9986936642717178\n","Multi-Layer Perceptron Classifier Sensitivity on Test Set = 0.759493670886076\n","Multi-Layer Perceptron Classifier Specificity on Test Set = 0.75625\n","Optimal Parameters:\n","   Hidden Layer Configuration: (35, 5, 25)\n","      Number of Layers: 3\n","      Layer 1 Size: 35 Neurons\n","      Layer 2 Size: 5 Neurons\n","      Layer 3 Size: 25 Neurons\n","   Activation Function: relu\n","   Solver for Weight Optimization: sgd\n","   Alpha: 1e-06\n","Average Runtime of Multi-Layer Perceptron Classifer on Test Set = 0.0016 seconds\n"]}]},{"cell_type":"code","source":["#Train the Decision Tree Classifier\n","def DT_Classifier():\n","\n","  print(\"Training the Decision Tree Classifier!\\n\")\n","\n","  optimal_depth = 4\n","  optimal_leaves = 4\n","\n","  #Parameter sweep for max depth\n","  print(\"Parameter sweep for optimal depth of tree...\")\n","  max_depth = [3,4,5,6,7,8,9,10,11,12,13,14]\n","  acc = 0.0\n","  for i in max_depth:\n","    clf = DecisionTreeClassifier(max_leaf_nodes=optimal_leaves, max_depth=i)\n","    clf = clf.fit(x_train, y_train)\n","    y_pred_val = clf.predict(x_val)\n","    acc_val = accuracy_score(y_val, y_pred_val)\n","    if acc_val > acc:\n","      optimal_depth = i\n","    print('  Accuracy in validation set:', acc_val, 'max depth:', i)\n","  print(\"\\n\")\n","\n","  #Parameter sweep for max leaf nodes\n","  print(\"Parameter sweep for optimal leaf nodes in the tree...\")\n","  max_leaves = [3,4,5,6,7,8,9,10]\n","  acc = 0.0\n","  for i in max_leaves:\n","    clf = DecisionTreeClassifier(max_leaf_nodes=i, max_depth=optimal_depth)\n","    clf = clf.fit(x_train, y_train)\n","    y_pred_val = clf.predict(x_val)\n","    acc_val = accuracy_score(y_val, y_pred_val)\n","    if acc_val > acc:\n","      optimal_leaves = i\n","    print('  Accuracy in validation set:', acc_val, 'max leaf nodes:', i)\n","  print(\"\\n\")\n","\n","  clf = DecisionTreeClassifier(max_leaf_nodes=optimal_leaves, max_depth=optimal_depth)\n","  clf = clf.fit(x_train, y_train)\n","\n","  # Compute the accuracy on the training set and test set\n","  train_accuracy = clf.score(x_train, y_train)\n","\n","  #Find the average runtime on the testing set\n","  num_runs = 50\n","  avg_time_DT = 0.0\n","  for i in range(0, num_runs):\n","    start_time = time.time()\n","    test_accuracy = clf.score(x_test, y_test)\n","    avg_time_DT += (time.time() - start_time)\n","  avg_time_DT /= num_runs\n","  avg_time_DT = str(round(avg_time_DT, 4))\n","\n","  #Calculate sensitivity and specificity metrics\n","  y_pred_DT = clf.predict(x_test)\n","  tn, fp, fn, tp = confusion_matrix(y_test, y_pred_DT).ravel()\n","  specificity_DT = tn / (tn+fp)\n","  sensitivity_DT = tp / (tp+fn)\n","\n","  print(\"Decision Tree Classifier Accuracy on Test Set = \" + str(test_accuracy))\n","  print(\"Decision Tree Classifier Accuracy on Training Set = \" + str(train_accuracy))\n","  print(\"Decision Tree Classifier Sensitivity on Test Set = \" + str(sensitivity_DT))\n","  print(\"Decision Tree Classifier Specificity on Test Set = \" + str(specificity_DT))\n","  print(\"Max Depth of Decision Tree Classifier = \" + str(optimal_depth))\n","  print(\"Max Leaves in Decision Tree Classifier = \" + str(optimal_leaves))\n","  print(\"Average Runtime of Decision Tree Classifer on Test Set = \" + str(avg_time_DT) + \" seconds\")\n","\n","DT_Classifier()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"me8YF0MQSUmQ","executionInfo":{"status":"ok","timestamp":1651856951914,"user_tz":240,"elapsed":11870,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"bb1c69af-c476-444b-c989-b05ce0149806"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the Decision Tree Classifier!\n","\n","Parameter sweep for optimal depth of tree...\n","  Accuracy in validation set: 0.6531365313653137 max depth: 3\n","  Accuracy in validation set: 0.6531365313653137 max depth: 4\n","  Accuracy in validation set: 0.6531365313653137 max depth: 5\n","  Accuracy in validation set: 0.6531365313653137 max depth: 6\n","  Accuracy in validation set: 0.6531365313653137 max depth: 7\n","  Accuracy in validation set: 0.6531365313653137 max depth: 8\n","  Accuracy in validation set: 0.6531365313653137 max depth: 9\n","  Accuracy in validation set: 0.6531365313653137 max depth: 10\n","  Accuracy in validation set: 0.6531365313653137 max depth: 11\n","  Accuracy in validation set: 0.6531365313653137 max depth: 12\n","  Accuracy in validation set: 0.6531365313653137 max depth: 13\n","  Accuracy in validation set: 0.6531365313653137 max depth: 14\n","\n","\n","Parameter sweep for optimal leaf nodes in the tree...\n","  Accuracy in validation set: 0.6125461254612546 max leaf nodes: 3\n","  Accuracy in validation set: 0.6531365313653137 max leaf nodes: 4\n","  Accuracy in validation set: 0.6531365313653137 max leaf nodes: 5\n","  Accuracy in validation set: 0.6531365313653137 max leaf nodes: 6\n","  Accuracy in validation set: 0.6826568265682657 max leaf nodes: 7\n","  Accuracy in validation set: 0.6752767527675276 max leaf nodes: 8\n","  Accuracy in validation set: 0.7047970479704797 max leaf nodes: 9\n","  Accuracy in validation set: 0.7084870848708487 max leaf nodes: 10\n","\n","\n","Decision Tree Classifier Accuracy on Test Set = 0.6509433962264151\n","Decision Tree Classifier Accuracy on Training Set = 0.720444154147616\n","Decision Tree Classifier Sensitivity on Test Set = 0.6962025316455697\n","Decision Tree Classifier Specificity on Test Set = 0.60625\n","Max Depth of Decision Tree Classifier = 14\n","Max Leaves in Decision Tree Classifier = 10\n","Average Runtime of Decision Tree Classifer on Test Set = 0.0005 seconds\n"]}]},{"cell_type":"code","source":["#Train the Random Forests Classifier\n","def RF_Classifier():\n","\n","  print(\"Training the Random Forests Classifier!\\n\")\n","\n","  n_estimators_list = [50,80,120,160,200]\n","  criterion_list = ['gini', 'entropy']\n","  max_features_list = ['auto', 'sqrt', 'log2']\n","  max_depth_list = [5, 7, 9]\n","  max_leaf_nodes_list = [10]\n","  params_grid = {\n","      'n_estimators': n_estimators_list,\n","      'criterion': criterion_list,\n","      'max_features': max_features_list,\n","      'max_depth': max_depth_list,\n","      'max_leaf_nodes': max_leaf_nodes_list\n","  }\n","\n","  def my_roc_auc_score(model, X, y): return metrics.roc_auc_score(y, model.predict(X))\n","  num_combinations = 1\n","  for k in params_grid.keys(): num_combinations *= len(params_grid[k])\n","\n","  print('Number of combinations = ', num_combinations)\n","\n","  #params_grid\n","  model_rf = GridSearchCV(estimator=RandomForestClassifier(),\n","                          param_grid=params_grid,\n","                          cv=3,\n","                          scoring=my_roc_auc_score,\n","                          return_train_score=True,\n","                          verbose=4)\n","\n","  model_rf.fit(x_train, y_train)\n","\n","  best_params = model_rf.best_params_\n","  print('Random Forest Classifier Training Complete! Best parameters are:', best_params)\n","  print(\"\\n\")\n","\n","  best_criterion = best_params['criterion']\n","  best_depth = best_params['max_depth']\n","  best_features = best_params['max_features']\n","  best_nodes = best_params['max_leaf_nodes']\n","  best_estimators = best_params['n_estimators']\n","\n","  clf = RandomForestClassifier(max_leaf_nodes=best_nodes, max_depth=best_depth, n_estimators=best_estimators, criterion=best_criterion, max_features=best_features)\n","  clf = clf.fit(x_train, y_train)\n","\n","  # Compute the accuracy on the training set and test set\n","  train_accuracy = clf.score(x_train, y_train)\n","\n","  #Find the average runtime on the testing set\n","  num_runs = 50\n","  avg_time_RF = 0.0\n","  for i in range(0, num_runs):\n","    start_time = time.time()\n","    test_accuracy = clf.score(x_test_val, y_test_val)\n","    avg_time_RF += (time.time() - start_time)\n","  avg_time_RF /= num_runs\n","  avg_time_RF = str(round(avg_time_RF, 4))\n","\n","  #Calculate sensitivity and specificity metrics\n","  y_pred_RF = clf.predict(x_test_val)\n","  tn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_RF).ravel()\n","  specificity_RF = tn / (tn+fp)\n","  sensitivity_RF = tp / (tp+fn)\n","\n","  print(\"Random Forest Classifier Accuracy on Test Set = \" + str(test_accuracy))\n","  print(\"Random Forest Classifier Accuracy on Training Set = \" + str(train_accuracy))\n","  print(\"Random Forest Classifier Sensitivity on Test Set = \" + str(sensitivity_RF))\n","  print(\"Random Forest Classifier Specificity on Test Set = \" + str(specificity_RF))\n","  print(\"Average Runtime of Random Forest Classifer on Test Set = \" + str(avg_time_RF) + \" seconds\")\n","\n","RF_Classifier()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KF8V83LVWKcl","executionInfo":{"status":"ok","timestamp":1651858503065,"user_tz":240,"elapsed":418847,"user":{"displayName":"Mark Lee","userId":"14543298645444410514"}},"outputId":"b0623dd2-7c8e-4541-c16b-48cff04a0c49"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the Random Forests Classifier!\n","\n","Number of combinations =  90\n","Fitting 3 folds for each of 90 candidates, totalling 270 fits\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.826, test=0.748) total time=   0.5s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.860, test=0.688) total time=   0.5s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.844, test=0.690) total time=   0.5s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.844, test=0.741) total time=   0.8s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.859, test=0.700) total time=   0.8s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.842, test=0.702) total time=   0.8s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.836, test=0.745) total time=   1.1s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.856, test=0.706) total time=   1.1s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.839, test=0.716) total time=   1.1s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.838, test=0.757) total time=   1.5s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.858, test=0.696) total time=   1.5s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.839, test=0.700) total time=   1.5s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.845, test=0.753) total time=   1.9s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.858, test=0.696) total time=   1.9s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.834, test=0.700) total time=   1.9s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.835, test=0.734) total time=   0.5s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.851, test=0.702) total time=   0.5s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.835, test=0.716) total time=   0.5s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.834, test=0.736) total time=   0.8s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.854, test=0.706) total time=   0.8s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.842, test=0.704) total time=   0.8s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.837, test=0.757) total time=   1.1s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.863, test=0.706) total time=   1.1s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.847, test=0.704) total time=   1.1s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.833, test=0.755) total time=   1.5s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.859, test=0.704) total time=   1.5s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.838, test=0.708) total time=   1.5s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.829, test=0.741) total time=   2.2s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.853, test=0.698) total time=   2.8s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.845, test=0.704) total time=   3.7s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.819, test=0.740) total time=   0.4s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.837, test=0.686) total time=   0.4s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.819, test=0.686) total time=   0.4s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.817, test=0.747) total time=   0.5s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.837, test=0.690) total time=   0.5s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.822, test=0.690) total time=   0.4s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.821, test=0.753) total time=   0.5s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.847, test=0.698) total time=   0.5s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.822, test=0.692) total time=   0.5s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.814, test=0.745) total time=   0.7s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.830, test=0.704) total time=   0.7s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.833, test=0.704) total time=   0.7s\n","[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.806, test=0.753) total time=   0.9s\n","[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.844, test=0.692) total time=   0.9s\n","[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.818, test=0.704) total time=   0.9s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.822, test=0.751) total time=   0.5s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.839, test=0.688) total time=   0.5s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.828, test=0.702) total time=   0.6s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.817, test=0.755) total time=   0.9s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.852, test=0.690) total time=   0.9s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.821, test=0.712) total time=   0.9s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.810, test=0.745) total time=   1.3s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.839, test=0.704) total time=   1.3s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.819, test=0.696) total time=   1.3s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.826, test=0.736) total time=   1.7s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.850, test=0.703) total time=   1.7s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.822, test=0.694) total time=   1.7s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.827, test=0.747) total time=   2.1s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.843, test=0.719) total time=   2.1s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.826, test=0.702) total time=   2.1s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.824, test=0.743) total time=   0.5s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.840, test=0.711) total time=   0.5s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.824, test=0.715) total time=   0.6s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.828, test=0.732) total time=   0.8s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.841, test=0.690) total time=   0.8s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.831, test=0.719) total time=   0.9s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.827, test=0.737) total time=   1.2s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.844, test=0.688) total time=   1.3s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.829, test=0.706) total time=   1.3s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.827, test=0.751) total time=   1.7s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.845, test=0.711) total time=   1.7s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.829, test=0.686) total time=   1.7s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.822, test=0.749) total time=   2.1s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.851, test=0.702) total time=   2.1s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.821, test=0.694) total time=   2.2s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.800, test=0.745) total time=   0.3s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.815, test=0.696) total time=   0.3s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.806, test=0.680) total time=   0.3s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.801, test=0.755) total time=   0.4s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.810, test=0.692) total time=   0.4s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.812, test=0.696) total time=   0.5s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.812, test=0.738) total time=   0.6s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.824, test=0.717) total time=   0.6s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.805, test=0.682) total time=   0.6s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.809, test=0.741) total time=   0.8s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.827, test=0.703) total time=   0.8s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.803, test=0.696) total time=   0.8s\n","[CV 1/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.809, test=0.761) total time=   1.0s\n","[CV 2/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.829, test=0.705) total time=   1.0s\n","[CV 3/3] END criterion=gini, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.817, test=0.704) total time=   1.0s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.820, test=0.747) total time=   0.6s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.832, test=0.698) total time=   0.6s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.823, test=0.708) total time=   0.6s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.813, test=0.749) total time=   0.9s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.839, test=0.705) total time=   0.9s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.819, test=0.706) total time=   1.0s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.822, test=0.747) total time=   1.3s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.834, test=0.694) total time=   1.4s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.816, test=0.713) total time=   1.4s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.820, test=0.749) total time=   1.8s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.850, test=0.703) total time=   1.8s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.823, test=0.700) total time=   1.9s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.825, test=0.759) total time=   2.2s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.837, test=0.694) total time=   2.2s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.815, test=0.702) total time=   2.3s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.814, test=0.751) total time=   0.6s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.836, test=0.705) total time=   0.6s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.809, test=0.694) total time=   0.6s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.824, test=0.749) total time=   0.9s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.840, test=0.707) total time=   0.9s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.814, test=0.698) total time=   0.9s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.821, test=0.753) total time=   1.3s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.835, test=0.688) total time=   1.4s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.820, test=0.705) total time=   1.4s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.822, test=0.741) total time=   1.8s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.839, test=0.719) total time=   1.8s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.813, test=0.694) total time=   1.9s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.819, test=0.751) total time=   2.2s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.847, test=0.705) total time=   2.3s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.818, test=0.700) total time=   2.3s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.801, test=0.741) total time=   0.3s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.816, test=0.706) total time=   0.3s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.808, test=0.690) total time=   0.3s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.796, test=0.734) total time=   0.5s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.822, test=0.688) total time=   0.4s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.805, test=0.700) total time=   0.4s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.807, test=0.749) total time=   0.6s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.821, test=0.690) total time=   0.6s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.804, test=0.692) total time=   0.6s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.802, test=0.755) total time=   0.9s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.826, test=0.694) total time=   0.9s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.805, test=0.698) total time=   0.9s\n","[CV 1/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.799, test=0.747) total time=   1.0s\n","[CV 2/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.829, test=0.705) total time=   1.0s\n","[CV 3/3] END criterion=gini, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.807, test=0.694) total time=   1.1s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.831, test=0.738) total time=   0.8s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.853, test=0.704) total time=   0.8s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.819, test=0.698) total time=   0.8s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.829, test=0.744) total time=   1.3s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.846, test=0.690) total time=   1.3s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.829, test=0.712) total time=   1.3s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.840, test=0.751) total time=   1.9s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.853, test=0.706) total time=   1.9s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.828, test=0.687) total time=   1.9s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.828, test=0.748) total time=   2.6s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.854, test=0.710) total time=   2.6s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.840, test=0.704) total time=   2.6s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.845, test=0.753) total time=   3.2s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.849, test=0.702) total time=   3.2s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.844, test=0.702) total time=   3.2s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.819, test=0.755) total time=   0.8s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.848, test=0.682) total time=   0.8s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.830, test=0.690) total time=   0.8s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.830, test=0.740) total time=   1.3s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.847, test=0.680) total time=   1.3s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.826, test=0.710) total time=   1.3s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.833, test=0.755) total time=   1.9s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.852, test=0.700) total time=   1.9s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.828, test=0.687) total time=   1.9s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.829, test=0.732) total time=   2.5s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.859, test=0.706) total time=   2.6s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.829, test=0.698) total time=   2.6s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.828, test=0.755) total time=   3.2s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.843, test=0.684) total time=   3.3s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.836, test=0.690) total time=   3.2s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.806, test=0.757) total time=   0.4s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.823, test=0.686) total time=   0.4s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.808, test=0.688) total time=   0.4s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.811, test=0.744) total time=   0.6s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.829, test=0.694) total time=   0.6s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.810, test=0.700) total time=   0.6s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.818, test=0.740) total time=   0.9s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.834, test=0.694) total time=   0.9s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.821, test=0.695) total time=   0.9s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.810, test=0.744) total time=   1.2s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.832, test=0.704) total time=   1.2s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.812, test=0.706) total time=   1.2s\n","[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.807, test=0.738) total time=   1.4s\n","[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.829, test=0.688) total time=   1.4s\n","[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.816, test=0.712) total time=   1.4s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.812, test=0.741) total time=   1.0s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.838, test=0.698) total time=   0.9s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.826, test=0.696) total time=   1.0s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.816, test=0.745) total time=   1.5s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.838, test=0.719) total time=   1.5s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.819, test=0.706) total time=   1.6s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.814, test=0.736) total time=   2.3s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.839, test=0.686) total time=   2.3s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.829, test=0.698) total time=   2.3s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.818, test=0.753) total time=   3.0s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.846, test=0.704) total time=   3.0s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.820, test=0.708) total time=   3.0s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.827, test=0.743) total time=   3.7s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.836, test=0.698) total time=   3.8s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.818, test=0.698) total time=   3.9s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.816, test=0.744) total time=   1.0s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.838, test=0.709) total time=   1.0s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.817, test=0.686) total time=   1.0s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.822, test=0.736) total time=   1.5s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.836, test=0.704) total time=   1.5s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.825, test=0.712) total time=   1.5s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.821, test=0.747) total time=   2.2s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.841, test=0.711) total time=   2.3s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.824, test=0.692) total time=   2.3s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.818, test=0.757) total time=   2.9s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.841, test=0.708) total time=   3.0s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.829, test=0.700) total time=   3.0s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.821, test=0.743) total time=   3.7s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.840, test=0.704) total time=   3.7s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.816, test=0.715) total time=   3.8s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.795, test=0.743) total time=   0.4s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.818, test=0.708) total time=   0.4s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.804, test=0.700) total time=   0.4s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.808, test=0.759) total time=   0.7s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.823, test=0.706) total time=   0.7s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.803, test=0.702) total time=   0.7s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.797, test=0.751) total time=   1.0s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.826, test=0.686) total time=   1.0s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.808, test=0.702) total time=   1.0s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.800, test=0.753) total time=   1.3s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.815, test=0.700) total time=   1.3s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.805, test=0.698) total time=   1.3s\n","[CV 1/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.797, test=0.753) total time=   1.6s\n","[CV 2/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.820, test=0.698) total time=   1.6s\n","[CV 3/3] END criterion=entropy, max_depth=7, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.811, test=0.684) total time=   1.7s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.816, test=0.730) total time=   1.0s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.835, test=0.700) total time=   1.0s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=50;, score=(train=0.814, test=0.716) total time=   1.1s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.816, test=0.747) total time=   1.6s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.847, test=0.713) total time=   1.7s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=80;, score=(train=0.812, test=0.696) total time=   1.7s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.822, test=0.755) total time=   2.4s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.838, test=0.692) total time=   2.4s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=120;, score=(train=0.813, test=0.704) total time=   2.5s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.820, test=0.741) total time=   3.2s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.838, test=0.705) total time=   3.2s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=160;, score=(train=0.804, test=0.704) total time=   3.4s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.817, test=0.745) total time=   4.0s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.841, test=0.701) total time=   4.0s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=auto, max_leaf_nodes=10, n_estimators=200;, score=(train=0.817, test=0.700) total time=   4.2s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.825, test=0.732) total time=   1.0s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.837, test=0.703) total time=   1.0s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=50;, score=(train=0.822, test=0.710) total time=   1.1s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.827, test=0.751) total time=   1.6s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.837, test=0.708) total time=   1.6s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=80;, score=(train=0.824, test=0.708) total time=   1.7s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.821, test=0.741) total time=   2.4s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.838, test=0.704) total time=   2.4s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=120;, score=(train=0.817, test=0.710) total time=   2.5s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.810, test=0.741) total time=   3.2s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.846, test=0.709) total time=   3.2s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=160;, score=(train=0.817, test=0.704) total time=   3.3s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.820, test=0.759) total time=   4.0s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.843, test=0.707) total time=   4.1s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=sqrt, max_leaf_nodes=10, n_estimators=200;, score=(train=0.814, test=0.708) total time=   4.2s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.802, test=0.757) total time=   0.4s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.825, test=0.690) total time=   0.5s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=50;, score=(train=0.809, test=0.712) total time=   0.4s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.797, test=0.749) total time=   0.7s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.821, test=0.700) total time=   0.7s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=80;, score=(train=0.802, test=0.700) total time=   0.7s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.796, test=0.738) total time=   1.0s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.820, test=0.684) total time=   1.1s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=120;, score=(train=0.803, test=0.696) total time=   1.1s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.801, test=0.747) total time=   1.4s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.818, test=0.690) total time=   2.1s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=160;, score=(train=0.801, test=0.698) total time=   1.9s\n","[CV 1/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.803, test=0.747) total time=   1.7s\n","[CV 2/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.827, test=0.696) total time=   1.7s\n","[CV 3/3] END criterion=entropy, max_depth=9, max_features=log2, max_leaf_nodes=10, n_estimators=200;, score=(train=0.798, test=0.700) total time=   1.8s\n","Random Forest Classifier Training Complete! Best parameters are: {'criterion': 'entropy', 'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 200}\n","\n","\n","Random Forest Classifier Accuracy on Test Set = 0.7232597623089984\n","Random Forest Classifier Accuracy on Training Set = 0.806009144350098\n","Random Forest Classifier Sensitivity on Test Set = 0.6608996539792388\n","Random Forest Classifier Specificity on Test Set = 0.7833333333333333\n","Average Runtime of Random Forest Classifer on Test Set = 0.0398 seconds\n"]}]}]}